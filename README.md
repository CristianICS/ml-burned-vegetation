# Clasificaci√≥n Machine Learning

Objetivo: clasificar vegetaci√≥n forestal y su subtipo de matorral alrededor de incendios forestales.

Los p√≠xeles que hayan sido quemados tras un incendio pasar√°n a considerarse matorral de la vegetaci√≥n preexistente al elaborar las etiquetas.

Estudiar c√≥mo var√≠a el acierto global y por categor√≠as seg√∫n:

- Tipo de clasificador (aplicar gridsearchcv)
- Tipo de preprocesamiento (secuencias de aumento y disminuci√≥n)
- N√∫mero de etiquetas incluidas
- N√∫mero de variables predictoras

## Variables predictoras

Se componen de las bandas de im√°genes Landsat harmonizadas (con las correcciones necesarias para reducir las diferencias espaciales entre los p√≠xeles de toda la serie). Existen im√°genes desde 1984 hasta 2023.

El procedimiento de c√°lculo es costoso, por lo que solo se calcularon datos para las zonas quemadas de Arag√≥n (`data/divided_tiles_by_area.gpkg`).

La clasificaci√≥n regional de la vegetaci√≥n a una escala espacial de 30 metros (p√≠xeles Landsat) presenta problemas complejos. Las firmas de la vegetaci√≥n se mezclan en p√≠xeles tan grandes, por lo que es m√°s dif√≠cil diferenciar entre tipos similares de vegetaci√≥n. Es por ello que se han utilizado variables con informaci√≥n adicional con el objetivo de complementar la informaci√≥n espectral.

Se dividen en dos tipos. En primer lugar, las derivadas del Modelo Digital de Elevaciones obtenido de los servicios WCS del PNOA. Se selecciona el r√°ster de 25 metros de resoluci√≥n espacial en EPSG:25830. La extracci√≥n se realiza utilizando las zonas que cuentan con im√°genes Landsat disponibles.

De las alturas se derivan:

- [Pendientes](https://gdal.org/en/stable/programs/gdal_raster_slope.html), en grados.
- Orientaciones [https://gdal.org/en/stable/programs/gdal_raster_aspect.html], entre 0 y 360 grados. Representan el el acimut (azimuth) hacia el cual se orientan las pendientes. El valor ser√° `nodata` si el valor de la pendiente es 0.
    - 0: Norte
    - 90: Este
    - 180: Sur
    - 270: Oeste
- Sombras ([Hillshade](https://gdal.org/en/stable/programs/gdal_raster_hillshade.html)), utilizando un acimut de 180 grados (sur) y una elevaci√≥n de 45 grados (sol de mediod√≠a).

Adem√°s, se ha obtenido la variable √°cido/b√°sico, capa de informaci√≥n binaria derivada del mapa geol√≥gico de Arag√≥n (1993). La divisi√≥n entre rocas b√°sicas y √°cidas se realiza con el objetivo de mejorar la clasificaci√≥n de la especie *Pinus pinaster*, con preferencia por sustratos b√°sicos. A los c√≥digos seleccionados como rocas b√°sicas se les asigna un 1, y a los clasificados como √°cidos un 2.

## Sets de etiquetas

El conjunto de etiquetas se ha obtenido en distintos a√±os de la serie temporal de im√°genes Landsat. Por este motivo, algunas etiquetas mantienen su posici√≥n a lo largo de varios a√±os. Sin embargo, si han sido observadas en varios a√±os tendr√°n dos valores, uno por cada a√±o, y los valores de las variables predictoras tendr√°n en cuenta dicha fecha para obtener las im√°genes Landsat.

### Vegetaci√≥n rala

Todos los conjuntos de etiquetas utilizados contienen datos de zonas con un porcentaje elevado de suelo desnudo mezclado con vegetaci√≥n rala o dispersa. Se utilizan los c√≥digos de python `extract_ground_points.py` y las funciones en `utils_il.py`. Adem√°s, el c√≥digo `create_dem.py` debe de haber sido utilizado para crear los MDEs con los que se obtiene la informaci√≥n de pendiente y orientaciones necesarias para la creaci√≥n de la imagen de Iluminaci√≥n. Tambi√©n deben descargarse las escenas del SIOSE con el c√≥digo "siose.py".

> Nota: Se han puesto fuera del archivo `utils.py` debido a que no se quiere abrir el m√≥dulo `gee` cada vez que se utilicen estas funciones.

Procedimiento:

1. Seleccionar los a√±os del SIOSE (2005, 2009, 2011 y 2014)
2. Crear un compuesto con im√°genes Landsat entre el 1 de junio y el 31 de julio en cada a√±o con informaci√≥n del SIOSE disponible.
3. Seleccionar los p√≠xeles con un valor de NDVI comprendido entre 0.08 y 0.15. Estos ser√°n los p√≠xeles candidatos que podr√≠an ser vegetaci√≥n rala.
4. Filtrar los puntos por distancia, eliminando aquellos con puntos a menos de 200 metros.
5. Obtener una imagen con el coseno del √°ngulo de incidencia local (IL) utilizando los datos de Azimuth y Elevaci√≥n solar promedio de las escenas utilizadas en el compuesto del NDVI.
6. Seleccionar de entre los p√≠xeles candidatos aquellos con un valor IL superior a 0.7.
7. Abrir la escena del SIOSE correspondiente, descargada del servicio WMS de lDEE. Se seleccionan aquellos p√≠xeles candidatos sobre categor√≠as de ocupaci√≥n del suelo "roquedo" y "suelo desnudo".

### Digitalizaci√≥n manual

El primer set de etiquetas fue definido por Andrea Acosta y Fernando P√©rez Cabello. Cuenta con 3132 etiquetas definidas. Se le agregaron puntos del IFN para poder aumentar las etiquetas.


1. Mejor m√©todo de pretratamiento

  - `RandomUnderSampler` vs `TomeKLinks` vs `None`
  - `SMOTE` vs `ADASYN` vs `None`


## Creaci√≥n de los conjuntos de datos



## Modelos

Nota: [La librer√≠a Scikit-Learn no puede ejecutarse en una GPU](https://stackoverflow.com/a/41568439). Es posible si se utiliza [cuml](https://docs.rapids.ai/api/cuml/stable/cuml_intro/), pero no lo he testado todav√≠a.

## Aumentar la eficiencia del c√≥digo

Gracias por describir tan bien tu flujo üëå. Entiendo por qu√© te est√° tardando tanto: est√°s haciendo muchas operaciones costosas (lectura de m√∫ltiples im√°genes muy grandes, reproyecciones y accesos p√≠xel a p√≠xel). Te paso varias sugerencias concretas para **mejorar la eficiencia** de tu proceso en Python con Rasterio y datos satelitales:

1. **Reducir accesos p√≠xel a p√≠xel (lo m√°s costoso)**

   * Evita recorrer los puntos uno a uno con `.index(row, col)` y `.read()` en cada iteraci√≥n.
   * Usa `rasterio.sample()` o mejor a√∫n **`rasterio.mask`** o **`rasterstats`** (o `rioxarray`) que permiten extraer todos los valores de un conjunto de puntos en bloque.
   * Otra opci√≥n: transformar las coordenadas de todos los puntos a filas/columnas de una vez (vectorizado con NumPy), y luego indexar directamente los arrays cargados.

---

2. **Lectura m√°s eficiente de los r√°steres**

   * Si trabajas con miles de archivos (1985‚Äì2023), evita abrir/cerrar con `rasterio.open()` en cada bucle.
     üëâ Usa `rioxarray.open_rasterio()` (que da un objeto `xarray.DataArray`) y permite trabajar con **chunks de dask** ‚Üí esto paraleliza y carga bajo demanda.
   * Considera **apilar las im√°genes en un solo stack** (NetCDF, Zarr o Cloud Optimized GeoTIFF). As√≠ no abres 1000 archivos, sino que consultas una sola estructura optimizada.

---

3. **Optimizar las sub√°reas**

   * Ahora divides en "sub√°reas de 20 mil hect√°reas".
     En lugar de eso, puedes **hacer un √≠ndice espacial** (por ejemplo con `geopandas.sjoin`) para relacionar cada punto con su tile/sub√°rea de forma previa. As√≠ reduces c√°lculos repetidos de ventanas.
   * Si sigues usando ventanas: aseg√∫rate de aprovechar `rasterio.windows.from_bounds` con NumPy slicing, que es bastante r√°pido.

---

4. **Promedios por estaci√≥n/a√±o**

   * No cargues im√°genes una por una para calcular medias.
     Usa `xarray` + `groupby("time.season")` + `.mean("time")` ‚Üí esto calcula todo de golpe, con paralelizaci√≥n.
   * Incluso si sigues con rasterio puro: mejor leer todos los arrays de esa estaci√≥n en un stack `np.array()` y aplicar `.mean(axis=0)` en memoria (si cabe).

---

5. **Paralelizaci√≥n**

   * Tu flujo es muy paralelizable: por **tile**, **sub√°rea** o incluso **a√±o/estaci√≥n**.
     Usa `concurrent.futures.ProcessPoolExecutor` o `dask.distributed` para explotar varios cores.
   * Si cada tile tarda 2‚Äì3 h, correr 10 tiles en paralelo en un servidor de 16‚Äì32 cores puede reducir dr√°sticamente el tiempo.

---

6. **Formatos de archivo**

   * Si las im√°genes son GeoTIFF cl√°sicos, convi√©rtelas a **Cloud Optimized GeoTIFF (COG)** ‚Üí mucho m√°s r√°pido para lecturas por ventanas (`window`).
   * Considera precalcular un **data cube** (ej. en formato Zarr). Zarr + Dask es pr√°cticamente est√°ndar para series largas de im√°genes satelitales.

---

7. **Bibliotecas especializadas**

   * \[`xarray` + `rioxarray` + `dask`] ‚Üí mejor combinaci√≥n para time series + raster.
   * \[`geopandas` + `rasterstats`/`xarray-spatial`] ‚Üí extracci√≥n en puntos m√°s eficiente.
   * \[`pyogrio`] (m√°s r√°pido que fiona para leer vectores).

---

## ‚ö° Ejemplo de enfoque m√°s eficiente (esquema con xarray)

```python
import rioxarray
import geopandas as gpd

# 1. Cargar puntos
points = gpd.read_file("puntos.gpkg")

# 2. Abrir stack de im√°genes con dask
stack = rioxarray.open_rasterio(
    "imagenes.zarr",  # o varios COGs con `open_mfdataset`
    chunks={"x": 1024, "y": 1024, "time": 1}
)

# 3. Agrupar por estaci√≥n y a√±o
seasonal_means = stack.groupby("time.season").mean("time")

# 4. Extraer valores en puntos
# rioxarray tiene un m√©todo .sel_points / o usar rasterio.sample en bloque
vals = [stack.sel(x=p.x, y=p.y, method="nearest").values for p in points.geometry]
```

Con `dask`, los c√°lculos se hacen en paralelo y s√≥lo se leen los fragmentos de disco necesarios.

---

üëâ Resumen de lo m√°s efectivo para ti:

1. **No recorrer puntos uno a uno** ‚Üí usa `sample` o indexaci√≥n vectorizada.
2. **Agrupa y calcula medias en bloque** (no en bucles).
3. **Convierte a COG o Zarr y usa xarray+dask** para lectura eficiente y paralela.
4. **Paraleliza por tile/a√±o** en varios procesos.

---

```python
# Filtrar entre 2000-01-01 y 2010-12-31
subset = stack.sel(time=slice("2000-01-01", "2010-12-31"))

# Media en ese rango
mean_interval = subset.mean("time")
```

En lugar de guardar los archivos con zarr, que duplicar√≠a la informaci√≥n, existen dos opciones m√°s interesantes. Abrir los datos con xopenarray por season o crear Cloud Optimized Geotiffs.

üíØ Tu preocupaci√≥n es muy v√°lida:
cuando pasas de miles de **GeoTIFFs** a un **Zarr ‚Äústackeado‚Äù**, efectivamente est√°s **duplicando todo** el volumen de datos en disco, y en sat√©lite eso puede ser teras.

La clave est√° en **no duplicar**, sino construir un **cat√°logo / √≠ndice** que apunte a los archivos existentes y permita a `xarray+dask` tratarlos como si fueran un solo ‚Äúdata cube‚Äù.

---

## üîë Alternativas a escribir un Zarr duplicado

### 1. **Abrir directamente los TIFFs con `open_mfdataset`**

`xarray` puede abrir m√∫ltiples TIFFs (usando `rioxarray.open_rasterio`) y tratarlos como un dataset unificado.

```python
import xarray as xr
import rioxarray
import glob
import re
from datetime import datetime

files = sorted(glob.glob("/ruta/tile_001/*.tif"))

# Extraer fechas desde nombres
def get_time(fname):
    match = re.search(r"(\d{8})", fname)
    return datetime.strptime(match.group(1), "%Y%m%d")

times = [get_time(f) for f in files]

# Abrir como un solo dataset sin escribir nada nuevo
rasters = [rioxarray.open_rasterio(f, chunks={"x": 1024, "y": 1024}).expand_dims(time=[t])
           for f, t in zip(files, times)]

stack = xr.concat(rasters, dim="time")
```

üëâ Aqu√≠ **no duplicas los datos**: cada TIFF se sigue leyendo desde su archivo original, pero `xarray+dask` los maneja como un stack.

---

### 2. **Usar Cloud Optimized GeoTIFF (COG)**

Si conviertes tus TIFF a **COG** (s√≥lo una vez, reemplazando los originales), no necesitas Zarr:

* COG ya permite acceso por bloques (ventanas).
* Dask los gestiona muy bien.

Herramientas: `gdal_translate -of COG input.tif output.tif`

---

### 3. **Crear un STAC catalog / Intake catalog**

En vez de un ‚Äústack f√≠sico‚Äù, puedes crear un **cat√°logo de metadatos** (STAC, Intake, even JSON+CSV) que describe:

* ruta del archivo
* fecha
* tile
* bandas disponibles

Despu√©s, `intake-stac` o `xarray` pueden leer directamente esos TIFFs ‚Äúon demand‚Äù.
Esto es lo que usan plataformas como Pangeo o Earth Engine: no duplican, s√≥lo indexan.

---

### 4. **Virtual stacking con `Rasterio VRT`**

Puedes generar un **VRT (Virtual Raster Tile)**, que es b√°sicamente un XML con la lista de tus TIFFs apilados.
Se crea con:

```bash
gdalbuildvrt -separate stack.vrt *.tif
```

Ese `.vrt` ocupa unos KB y act√∫a como un mosaico/stack virtual.
Luego puedes abrir `stack.vrt` con `rioxarray` y tratarlo como un multibanda.

üëâ Esto es s√∫per √∫til si lo que quieres es **unificar im√°genes** sin copiarlas.

---

## üìå Comparaci√≥n r√°pida

| M√©todo                     | Duplica datos        | Rendimiento                    | Portabilidad                    |
| -------------------------- | -------------------- | ------------------------------ | ------------------------------- |
| **Zarr**                   | ‚úÖ S√≠                 | üöÄ Muy alto                    | Python/Dask                     |
| **open\_mfdataset (lazy)** | ‚ùå No                 | ‚ö° Alto (depende de TIFF)       | Python                          |
| **COG**                    | ‚ùå No (si reemplazas) | üöÄ Muy alto                    | Est√°ndar en ecosistema sat√©lite |
| **STAC/Intake**            | ‚ùå No                 | ‚ö° Alto (on demand)             | Multiplataforma                 |
| **VRT**                    | ‚ùå No                 | ‚ö° Alto (GDAL depende de TIFFs) | GDAL, Rasterio                  |

---

## ‚úÖ Recomendaci√≥n pr√°ctica

* Si **no tienes espacio** para un segundo dataset ‚Üí usa **VRT** o **open\_mfdataset** (no duplican, solo indexan).
* Si despu√©s quieres mover tu flujo a la nube o clusters ‚Üí considera migrar a **COG + STAC** (est√°ndar abierto).

---

üëâ Pregunta: ¬øquieres que te prepare un ejemplo concreto con **GDAL VRT** (que unifica autom√°ticamente todos los TIFF de cada carpeta en un stack virtual que luego lees con `xarray`), o prefieres quedarte en el flujo con `xarray.open_mfdataset` sin generar archivos adicionales?

